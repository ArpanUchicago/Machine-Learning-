{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c55f039",
   "metadata": {},
   "source": [
    "#  Detect computer security breach using RNNs and LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946ef7e-c2c8-4f46-8d2a-16e92fd7024f",
   "metadata": {},
   "source": [
    "#1. Data Processing: This data set is a bit messy, so the preprocessing portion is largely a tutorial to make sure students have data ready for keras. \n",
    "\n",
    "a) Import the following libraries: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "107e3edb-a713-47f2-9ede-b613b2cccc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\apps\\anaconda\\lib\\site-packages (3.3.3)\n",
      "Requirement already satisfied: absl-py in c:\\apps\\anaconda\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\apps\\anaconda\\lib\\site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\apps\\anaconda\\lib\\site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\apps\\anaconda\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\apps\\anaconda\\lib\\site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\apps\\anaconda\\lib\\site-packages (from keras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\apps\\anaconda\\lib\\site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\apps\\anaconda\\lib\\site-packages (from optree->keras) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\apps\\anaconda\\lib\\site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\apps\\anaconda\\lib\\site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\apps\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: tensorflow in c:\\apps\\anaconda\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.63.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\apps\\anaconda\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\apps\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\apps\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\apps\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\apps\\anaconda\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\apps\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\apps\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\apps\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\apps\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\apps\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\apps\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\apps\\anaconda\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\apps\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\apps\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\apps\\anaconda\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\apps\\anaconda\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174e7eb-d6b5-4eca-bffb-99bfc2c993bc",
   "metadata": {},
   "source": [
    "b) We will read the code in slightly differently than before: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f407091c-88f9-461b-b4b0-d458be4686aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas\n",
    "\n",
    "import numpy\n",
    "import optparse\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from keras.layers import Embedding  \n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82625a-0d19-4757-bfcc-0d0b7caadc69",
   "metadata": {},
   "source": [
    "c) We then need to convert to a numpy.ndarray type: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42472384-6a2c-4326-b54d-df3b5e7ad462",
   "metadata": {},
   "source": [
    "d) Check the shape of the data set - it should be (26773, 2). Spend some time looking at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128833e-ad96-4fde-927d-57ccc22e52d5",
   "metadata": {},
   "source": [
    "e) Store all rows and the 0th index as the feature data: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331204b-ba57-4b85-8d14-f2740354a80f",
   "metadata": {},
   "source": [
    "f) Store all rows and index 1 as the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "47e273e5-bca9-443d-9f9a-163c3f770382",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pandas.read_csv(\"dev-access.csv\", engine='python', quotechar='|', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ccecedb-9241-4c56-be5b-7b8ed83c6abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5fe40656-ce80-4bb3-a256-89f8fba63ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (26773, 2)\n",
      "First 5 rows:\n",
      "Row:\n",
      "Column 0: {\"timestamp\":1502738402847,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"accept-language\":\"en-us\",\"accept-encoding\":\"gzip, deflate\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"referer\":\"http://localhost:8002/enter\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"content-type\":\"application/json\",\"content-length\":\"36\"},\"requestPayload\":{\"username\":\"Carl2\",\"password\":\"bo\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}\n",
      "Column 1: 0\n",
      "Row:\n",
      "Column 0: {\"timestamp\":1502738402849,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"47\"},\"requestPayload\":{\"username\":\"pafzah\",\"password\":\"worldburn432\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}\n",
      "Column 1: 0\n",
      "Row:\n",
      "Column 0: {\"timestamp\":1502738402852,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"205.49.83.118\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"44\"},\"requestPayload\":{\"username\":\"Panos1\",\"password\":\"najrijkom\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}\n",
      "Column 1: 0\n",
      "Row:\n",
      "Column 0: {\"timestamp\":1502738402852,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"205.49.83.118\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"accept-language\":\"en-us\",\"accept-encoding\":\"gzip, deflate\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"referer\":\"http://localhost:8002/enter\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"content-type\":\"application/json\",\"content-length\":\"47\"},\"requestPayload\":{\"username\":\"vuvpuvehu\",\"password\":\"password1\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}\n",
      "Column 1: 0\n",
      "Row:\n",
      "Column 0: {\"timestamp\":1502738402853,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"137.196.95.116\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"41\"},\"requestPayload\":{\"username\":\"Michele\",\"password\":\"mokgu\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}\n",
      "Column 1: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dataset:\", dataset.shape)\n",
    "print(\"First 5 rows:\")\n",
    "for row in dataset[:5]:\n",
    "    print(\"Row:\")\n",
    "    for column_idx, column_value in enumerate(row):\n",
    "        print(f\"Column {column_idx}: {column_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8090364-6736-484e-8801-83628f9e188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0]\n",
    "Y = dataset[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8617de9c-9a45-4103-bba2-b0f555b7627d",
   "metadata": {},
   "source": [
    "g) In the next step, we will clean up the predictors. This includes removing features that are not valuable, such as timestamp and source. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f056b2e8-7e3c-4f11-8267-6a96717a04d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(X):\n",
    "    # Quick hack to space out json elements\n",
    "    reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
    "    del reqJson['timestamp']\n",
    "    del reqJson['headers']\n",
    "    del reqJson['source']\n",
    "    del reqJson['route']\n",
    "    del reqJson['responsePayload']\n",
    "    X[index] = json.dumps(reqJson, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ecbf71-fe99-4659-bc94-22512455c891",
   "metadata": {},
   "source": [
    "h) We next will tokenize our data, which just means vectorizing our text. Given the data we will tokenize every character (thus char_level = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3869af90-cc60-46f0-82bf-488875419e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "# we will need this later\n",
    "num_words = len(tokenizer.word_index)+1\n",
    "X = tokenizer.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a56bba6-f8e7-4e65-84bc-43e141f00d42",
   "metadata": {},
   "source": [
    "i) Need to pad our data as each observation has a different length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bde348c2-ffed-458a-944b-cc6aa1791831",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_log_length = 1024\n",
    "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c56900-bedc-48f2-841e-11602cf6b7a2",
   "metadata": {},
   "source": [
    "j) Create your train set to be 75% of the data and your test set to be 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb9797c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (20079, 1024)\n",
      "Shape of X_test: (6694, 1024)\n",
      "Shape of y_train: (20079,)\n",
      "Shape of y_test: (6694,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Printing the shapes of the train and test sets\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab1b1f7-1096-469a-87e7-d3ca9539a71e",
   "metadata": {},
   "source": [
    "2. Model 1 - RNN: The first model will be a pretty minimal RNN with only an embedding layer, simple RNN and Dense layer. The next model we will add a few more layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b1940db-9dc7-42c7-8c7d-f8f962ea6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##adding embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8a432501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,161</span> (16.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,161\u001b[0m (16.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,161</span> (16.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,161\u001b[0m (16.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, SimpleRNN, Dense\n",
    "\n",
    "# Creating a new instance of a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Adding an Embedding layer\n",
    "model.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_log_length))\n",
    "\n",
    "# Adding a SimpleRNN layer\n",
    "model.add(SimpleRNN(units=32, activation='relu'))\n",
    "\n",
    "# Adding a Dense layer\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Building the model \n",
    "model.build(input_shape=(num_words, max_log_length))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Printing the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2755a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6fc12696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_13 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_9 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,161</span> (16.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,161\u001b[0m (16.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,161</span> (16.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,161\u001b[0m (16.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing the model summary\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34dabead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Converting y_train to integer data type\n",
    "y_train = y_train.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d2ed929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 111ms/step - accuracy: 0.7048 - loss: 0.5508 - val_accuracy: 0.7532 - val_loss: 0.4341\n",
      "Epoch 2/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - accuracy: 0.7456 - loss: 0.4415 - val_accuracy: 0.7532 - val_loss: 0.4339\n",
      "Epoch 3/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - accuracy: 0.7491 - loss: 0.4386 - val_accuracy: 0.7532 - val_loss: 0.4328\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model on the training data\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=128, validation_split=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "068f463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Converting y_test to integers\n",
    "y_test = y_test.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b39601be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7416 - loss: 0.4340\n",
      "Test Loss: 0.43643516302108765\n",
      "Test Accuracy: 0.740962028503418\n"
     ]
    }
   ],
   "source": [
    "# Using the .evaluate() method to get the loss value and accuracy value on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "# Printing the loss value and accuracy value\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ec345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###3) Model 2 - LSTM + Dropout Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8284af4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "\n",
    "# Creating a new instance of a Sequential model\n",
    "model_lstm = Sequential()\n",
    "\n",
    "# Adding an Embedding layer\n",
    "model_lstm.add(Embedding(input_dim=num_words, output_dim=32, input_length=max_log_length))\n",
    "\n",
    "# Adding an LSTM layer with recurrent dropout\n",
    "model_lstm.add(LSTM(units=64, recurrent_dropout=0.5))\n",
    "\n",
    "# Adding a Dropout layer\n",
    "model_lstm.add(Dropout(0.5))\n",
    "\n",
    "# Adding a Dense layer\n",
    "model_lstm.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Building the model\n",
    "model_lstm.build(input_shape=(num_words, max_log_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "421da128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_31\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_31\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_30 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_23 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │        \u001b[38;5;34m24,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,945</span> (105.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,945\u001b[0m (105.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,945</span> (105.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,945\u001b[0m (105.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 708ms/step - accuracy: 0.6450 - loss: 0.6119 - val_accuracy: 0.7532 - val_loss: 0.4441\n",
      "Epoch 2/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 702ms/step - accuracy: 0.7395 - loss: 0.4591 - val_accuracy: 0.7532 - val_loss: 0.4378\n",
      "Epoch 3/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 670ms/step - accuracy: 0.7391 - loss: 0.4470 - val_accuracy: 0.7532 - val_loss: 0.4330\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 136ms/step - accuracy: 0.7416 - loss: 0.4337\n",
      "Test Loss: 0.436225950717926\n",
      "Test Accuracy: 0.740962028503418\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Printing the model summary\n",
    "print(model_lstm.summary())\n",
    "\n",
    "# Fitting the model on the training data\n",
    "history_lstm = model_lstm.fit(X_train, y_train, epochs=3, batch_size=128, validation_split=0.25)\n",
    "\n",
    "# Evaluating the model on test data\n",
    "loss_lstm, accuracy_lstm = model_lstm.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "# Printing the loss value and accuracy value\n",
    "print(\"Test Loss:\", loss_lstm)\n",
    "print(\"Test Accuracy:\", accuracy_lstm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac4d47",
   "metadata": {},
   "source": [
    "##4) Recurrent Neural Net Model 3: Build Your Own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "37bb6f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout\n",
    "\n",
    "# Defining the model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(num_words, 128, input_length=max_log_length))  # Adjust parameters as needed\n",
    "\n",
    "# Stacking 2 LSTM layers\n",
    "model.add(LSTM(64, return_sequences=True))  # 64 units, return sequences for next LSTM\n",
    "model.add(Dropout(0.2))  # Add dropout for regularization\n",
    "\n",
    "model.add(LSTM(32))  # 32 units for final layer\n",
    "\n",
    "# New Layer: Dense layer with ReLU activation \n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Calling build (optional in this case)\n",
    "model.build(input_shape=(num_words, max_log_length))  # Provide input shape if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c36528c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_31 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │         \u001b[38;5;34m8,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_24 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1024\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)                │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,369</span> (290.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m74,369\u001b[0m (290.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">74,369</span> (290.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m74,369\u001b[0m (290.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 2s/step - accuracy: 0.6971 - loss: 0.5710 - val_accuracy: 0.7532 - val_loss: 0.4392\n",
      "Epoch 2/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 2s/step - accuracy: 0.7477 - loss: 0.4425 - val_accuracy: 0.7532 - val_loss: 0.4341\n",
      "Epoch 3/3\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 2s/step - accuracy: 0.7434 - loss: 0.4436 - val_accuracy: 0.7532 - val_loss: 0.4320\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 394ms/step - accuracy: 0.7416 - loss: 0.4331\n",
      "Test Loss: 0.4355980157852173\n",
      "Test Accuracy: 0.740962028503418\n"
     ]
    }
   ],
   "source": [
    "# Compiling the model with a new optimizer (e.g., RMSprop)\n",
    "model.compile(loss='binary_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
    "\n",
    "# Printing  the model summary\n",
    "model.summary()\n",
    "\n",
    "# Training the model with validation split\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=128, validation_split=0.25)\n",
    "\n",
    "# Evaluating the model on test data\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, batch_size=128)\n",
    "\n",
    "# Printing test loss and accuracy\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a1155",
   "metadata": {},
   "source": [
    "Conceptual Questions: \n",
    "\n",
    "5) Explain the difference between the relu activation function and the sigmoid activation function.\n",
    "\n",
    "Ans: Both ReLU (Rectified Linear Unit) and sigmoid are popular activation functions used in artificial neural networks.\n",
    "Sigmoid squashes any real number between positive and negative infinity into a value between 0 and 1. It produces an S-shaped curve.The output values range continuously from 0 to 1.\n",
    "ReLU sets any negative input value to zero and keeps positive input values unchanged. It essentially acts like a threshold function.The output can be either 0 ( fo negative inputs)  or 1 (for poitive inputs). \n",
    " \n",
    "6) Describe what one epoch actually is (epoch was a parameter used in the .fit() method).\n",
    "\n",
    "Ans: In machine learning, an epoch represents a single, complete cycle of training our model on the entire dataset. It's like a student going through their entire textbook (training data) once. During this epoch, each data point is fed through the model, predictions are made, and errors are calculated. The model then uses this error information to adjust its internal parameters.  Multiple epochs allow the model to learn progressively from the data.\n",
    "\n",
    "7) Explain how dropout works (you can look at the keras code and/or documentation) for (a) training, and (b) test data sets.\n",
    "\n",
    "Ans: Dropout is a regularization technique to prevent neural networks from overfitting during training.In out code we used dropout rate of 0.2. During training, 20% (0.2 dropout rate) of the activations in the previous LSTM layer  are randomly chosen to be set to zero.Dropout discourages the network from relying too heavily on specific neurons. This helps prevent overfitting and improves the model's ability to generalize to unseen data.\n",
    "The dropout layer acts like a training switch to prevent our RNN from overfitting on login data. During training, it randomly removes 20% of the analysts (activations from the previous layer) working on each login attempt. This forces the remaining analysts to collaborate effectively and learn to solve the problem without relying on specific colleagues. To compensate for the missing analysts, the workload of the remaining ones is slightly increased. This discourages the network from becoming overly reliant on any particular neuron and helps it generalize better to unseen data. However, during testing on unseen login attempts, the dropout switch is turned off. All analysts work together, and their contributions are used directly without any adjustments, ensuring the most accurate predictions possible.\n",
    "\n",
    "\n",
    "8) Explain why problems such as this homework assignment are better modeled with RNNs than CNNs. What type of problem will CNNs outperform RNNs on?\n",
    "\n",
    "Ans: RNNs excel at handling sequential information like login attempts, allowing them to capture temporal relationships (e.g., frequent attempts from a new location).RNNs can efficiently process these sequences of different lengths.\n",
    "CNNs are powerful for analyzing data arranged in grids, like images or structured time series.\n",
    "CNNs focus on capturing local patterns within the data, making them suitable for tasks where features are localized (e.g., identifying objects in images).\n",
    "\n",
    "9) Explain what RNN problem is solved using LSTM and briefly describe how.\n",
    "\n",
    "Ans : LSTMs overcome the vanishing gradient problem by selectively controlling the flow of information and maintaining long-term dependencies within their cell state.Speech Recognition,Machine Translation,Time Series Forecasting,Video Analysis.STMs introduce a special gating mechanism that controls the flow of information within the network. This mechanism allows LSTMs to:Select Relevant Information: LSTMs use gates (forget gate, input gate, and output gate) to selectively remember or forget information from previous steps. The forget gate decides what information to discard from the cell state (internal memory), the input gate controls what new information to store, and the output gate determines what information from the cell state to use in the current output.\n",
    "Maintain Long-Term Dependencies: The cell state in LSTMs acts like a memory buffer that can store information for extended periods. Unlike the hidden state in a regular RNN, the cell state's information is not directly overwritten but selectively updated through the gating mechanism. This allows LSTMs to learn and retain information from distant parts of the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "01c8d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_data_for_NN(\n",
    "    data: pd.DataFrame, Y_var: str, lag: int, test_ratio: float\n",
    ") -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "  \"\"\"Function to return lagged time series data after train-test split\n",
    "\n",
    "  Args:\n",
    "      data (pd.DataFrame): Raw time series data frame\n",
    "      Y_var (str): String with the name of y variable\n",
    "      lag (int): number of lagged records to consider\n",
    "      test_ratio (float): ratio of data to consider for test set\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.array, np.array, np.array, np.array]: Lagged and split numpy arrays\n",
    "  \"\"\"\n",
    "  y = data[Y_var].tolist()\n",
    "\n",
    "  X, Y = [], []\n",
    "\n",
    "  if len(y) - lag <= 0:\n",
    "    X.append(y)\n",
    "  else:\n",
    "    for i in range(len(y) - lag):\n",
    "      Y.append(y[i + lag])\n",
    "      X.append(y[i: (i + lag)])\n",
    "\n",
    "  X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "  # Reshaping the X array to an LSTM input shape\n",
    "  X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "  # Creating training and test sets\n",
    "  X_train = X\n",
    "  X_test = []\n",
    "\n",
    "  Y_train = Y\n",
    "  Y_test = []\n",
    "\n",
    "  if test_ratio > 0:\n",
    "    index = round(len(X) * test_ratio)\n",
    "    X_train = X[: (len(X) - index)]\n",
    "    X_test = X[-index:]\n",
    "\n",
    "    Y_train = Y[: (len(X) - index)]\n",
    "    Y_test = Y[-index:]\n",
    "\n",
    "  return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "26cf1162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Datetime     0\n",
      "DAYTON_MW    0\n",
      "dtype: int64\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 4299803.5000 - val_loss: 4185320.7500\n",
      "Epoch 2/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4208990.5000 - val_loss: 4104090.2500\n",
      "Epoch 3/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4135594.7500 - val_loss: 4024422.7500\n",
      "Epoch 4/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 4060600.0000 - val_loss: 3945608.7500\n",
      "Epoch 5/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3974140.7500 - val_loss: 3867569.7500\n",
      "Epoch 6/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3897182.0000 - val_loss: 3790339.0000\n",
      "Epoch 7/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3818366.7500 - val_loss: 3713962.5000\n",
      "Epoch 8/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3737175.0000 - val_loss: 3638369.2500\n",
      "Epoch 9/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3663213.5000 - val_loss: 3563589.2500\n",
      "Epoch 10/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3591011.7500 - val_loss: 3489666.2500\n",
      "Epoch 11/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3518870.5000 - val_loss: 3416537.5000\n",
      "Epoch 12/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3443740.7500 - val_loss: 3344212.7500\n",
      "Epoch 13/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3366826.5000 - val_loss: 3272670.0000\n",
      "Epoch 14/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3296802.7500 - val_loss: 3201983.0000\n",
      "Epoch 15/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3232109.2500 - val_loss: 3132103.0000\n",
      "Epoch 16/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3159330.7500 - val_loss: 3063017.2500\n",
      "Epoch 17/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3094095.5000 - val_loss: 2994777.7500\n",
      "Epoch 18/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 3013710.0000 - val_loss: 2927299.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 2954766.0000 - val_loss: 2860689.5000\n",
      "Epoch 20/20\n",
      "\u001b[1m3222/3222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - loss: 2879849.5000 - val_loss: 2794860.2500\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 858us/step\n",
      "Single LSTM with lag 3 hours - RMSE: 1671.7834\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 4283026.5000 - val_loss: 4077246.7500\n",
      "Epoch 2/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 4084842.2500 - val_loss: 3891369.7500\n",
      "Epoch 3/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 3890791.5000 - val_loss: 3712723.5000\n",
      "Epoch 4/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3717820.0000 - val_loss: 3539183.2500\n",
      "Epoch 5/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3546488.2500 - val_loss: 3370045.5000\n",
      "Epoch 6/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3372276.0000 - val_loss: 3205176.7500\n",
      "Epoch 7/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3200934.2500 - val_loss: 3044704.0000\n",
      "Epoch 8/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3047989.0000 - val_loss: 2888685.5000\n",
      "Epoch 9/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2889904.0000 - val_loss: 2736957.0000\n",
      "Epoch 10/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2736683.0000 - val_loss: 2589598.7500\n",
      "Epoch 11/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2585339.5000 - val_loss: 2446616.0000\n",
      "Epoch 12/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2442116.2500 - val_loss: 2308008.5000\n",
      "Epoch 13/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2309497.0000 - val_loss: 2173727.7500\n",
      "Epoch 14/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2184160.5000 - val_loss: 2043905.3750\n",
      "Epoch 15/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2046621.5000 - val_loss: 1910199.1250\n",
      "Epoch 16/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - loss: 1907644.6250 - val_loss: 1780960.8750\n",
      "Epoch 17/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1786652.0000 - val_loss: 1657065.1250\n",
      "Epoch 18/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1654814.1250 - val_loss: 1538039.0000\n",
      "Epoch 19/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1546809.2500 - val_loss: 1424097.8750\n",
      "Epoch 20/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1431212.8750 - val_loss: 1314983.2500\n",
      "\u001b[1m569/569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Single LSTM with lag 24 hours - RMSE: 1146.7271\n",
      "Single LSTM Model Summary (lag 24 hours):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_56\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_56\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_51 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_73 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,355</span> (122.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,355\u001b[0m (122.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,451</span> (40.82 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,451\u001b[0m (40.82 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,904</span> (81.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,904\u001b[0m (81.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv(\"DAYTON_hourly.csv\")\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "# Converting o datetime format\n",
    "data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
    "\n",
    "# Sorting Datetime for a time series order\n",
    "data.sort_values(by=\"Datetime\", inplace=True)\n",
    "\n",
    "# Defining target variable\n",
    "target_variable = \"DAYTON_MW\"\n",
    "\n",
    "# Defining values to test (3 hours and 24 hours)\n",
    "lag_values = [3, 24]\n",
    "\n",
    "# Looping thru different lag values to create data for various models\n",
    "for lag in lag_values:\n",
    "  # Split data into training and testing sets with a 15% test ratio\n",
    "  X_train, X_test, Y_train, Y_test = create_data_for_NN(data, target_variable, lag, 0.15)\n",
    "\n",
    "    \n",
    "  # Defining and fitting a single layer LTSM model\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(50, return_sequences=False, input_shape=(X_train.shape[1], 1)))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "\n",
    "  # Adding early stopping to prevent overfitting\n",
    "  early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "  history = model.fit(\n",
    "      X_train,\n",
    "      Y_train,\n",
    "      epochs=20,\n",
    "      validation_data=(X_test, Y_test),\n",
    "      callbacks=[early_stopping],\n",
    "  )\n",
    "\n",
    "  # Making predictions on test data\n",
    "  y_predicted = model.predict(X_test)\n",
    "\n",
    "  # Calculating RMSE on test data\n",
    "  rmse = mean_squared_error(Y_test, y_predicted, squared=False)\n",
    "  print(f\"Single LSTM with lag {lag} hours - RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Printing single LSTM model summary for this lag\n",
    "print(f\"Single LSTM Model Summary (lag {lag} hours):\")\n",
    "print(model.summary())  # Added printing the model summary\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e68be6",
   "metadata": {},
   "source": [
    "Fit a bidirectional LSTM with lag = 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "53988164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Datetime     0\n",
      "DAYTON_MW    0\n",
      "dtype: int64\n",
      "Epoch 1/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 8ms/step - loss: 4114158.0000 - val_loss: 3589439.2500\n",
      "Epoch 2/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 3489964.2500 - val_loss: 3021333.2500\n",
      "Epoch 3/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 2933061.0000 - val_loss: 2506704.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 2426050.7500 - val_loss: 2044606.8750\n",
      "Epoch 5/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 1974631.0000 - val_loss: 1634408.2500\n",
      "Epoch 6/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 1575862.5000 - val_loss: 1276008.2500\n",
      "Epoch 7/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 1226145.5000 - val_loss: 968679.6875\n",
      "Epoch 8/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 925594.7500 - val_loss: 712503.7500\n",
      "Epoch 9/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 678807.6250 - val_loss: 506620.0625\n",
      "Epoch 10/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 483755.0312 - val_loss: 350152.3438\n",
      "Epoch 11/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 335492.6250 - val_loss: 241569.3594\n",
      "Epoch 12/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 235421.8281 - val_loss: 178006.7812\n",
      "Epoch 13/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 179329.7031 - val_loss: 152537.0156\n",
      "Epoch 14/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 158238.5469 - val_loss: 149046.4219\n",
      "Epoch 15/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 155995.8438 - val_loss: 149153.5625\n",
      "Epoch 16/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 156652.2344 - val_loss: 149122.0000\n",
      "Epoch 17/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 156098.0312 - val_loss: 149150.0938\n",
      "Epoch 18/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 8ms/step - loss: 156537.4375 - val_loss: 149130.2969\n",
      "Epoch 19/20\n",
      "\u001b[1m3221/3221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 8ms/step - loss: 155402.1250 - val_loss: 149172.0312\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def create_data_for_NN(\n",
    "    data: pd.DataFrame, Y_var: str, lag: int, test_ratio: float\n",
    ") -> Tuple[np.array, np.array, np.array, np.array]:\n",
    "  \"\"\"Function to return lagged time series data after train-test split\n",
    "\n",
    "  Args:\n",
    "      data (pd.DataFrame): Raw time series data frame\n",
    "      Y_var (str): String with the name of y variable\n",
    "      lag (int): number of lagged records to consider\n",
    "      test_ratio (float): ratio of data to consider for test set\n",
    "\n",
    "  Returns:\n",
    "      Tuple[np.array, np.array, np.array, np.array]: Lagged and split numpy arrays\n",
    "  \"\"\"\n",
    "  y = data[Y_var].tolist()\n",
    "\n",
    "  X, Y = [], []\n",
    "\n",
    "  if len(y) - lag <= 0:\n",
    "    X.append(y)\n",
    "  else:\n",
    "    for i in range(len(y) - lag):\n",
    "      Y.append(y[i + lag])\n",
    "      X.append(y[i: (i + lag)])\n",
    "\n",
    "  X, Y = np.array(X), np.array(Y)\n",
    "\n",
    "  # Reshaping the X array to an LSTM input shape\n",
    "  X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "\n",
    "  # Creating training and test sets\n",
    "  X_train = X\n",
    "  X_test = []\n",
    "\n",
    "  Y_train = Y\n",
    "  Y_test = []\n",
    "\n",
    "  if test_ratio > 0:\n",
    "    index = round(len(X) * test_ratio)\n",
    "    X_train = X[: (len(X) - index)]\n",
    "    X_test = X[-index:]\n",
    "\n",
    "    Y_train = Y[: (len(X) - index)]\n",
    "    Y_test = Y[-index:]\n",
    "\n",
    "  return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "# Loading data\n",
    "data = pd.read_csv(\"DAYTON_hourly.csv\")\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# Converting Datetime to datetime format\n",
    "data[\"Datetime\"] = pd.to_datetime(data[\"Datetime\"])\n",
    "\n",
    "# Sorting by Datetime for a time series order\n",
    "data.sort_values(by=\"Datetime\", inplace=True)\n",
    "\n",
    "# Defining target variable\n",
    "target_variable = \"DAYTON_MW\"\n",
    "\n",
    "# Defining lag values to test\n",
    "lag_values = [3, 24]\n",
    "\n",
    "# Loop through different lag values to create data for various models\n",
    "for lag in lag_values:\n",
    "  # Split data into training and testing sets with a 15% test ratio\n",
    "  X_train, X_test, Y_train, Y_test = create_data_for_NN(data, target_variable, lag, 0.15)\n",
    "\n",
    "\n",
    "\n",
    "  # Defining and fitting a bidirectional LSTM model with lag 24 hours\n",
    "  if lag == 24:\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))  # No need for input_tensor argument\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=True))\n",
    "    model.add(LSTM(50))  # Second LSTM layer in the bidirectional architecture\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "    # Adding early stopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        Y_train,\n",
    "        epochs=20,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        callbacks=[early_stopping],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ec740ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidirectional LSTM Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_54\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_54\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_48 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │        \u001b[38;5;34m10,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_49 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_71 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">91,955</span> (359.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m91,955\u001b[0m (359.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,651</span> (119.73 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,651\u001b[0m (119.73 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61,304</span> (239.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m61,304\u001b[0m (239.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Printing the bidirectional LSTM model summary\n",
    "print(\"Bidirectional LSTM Model Summary:\")\n",
    "print(model.summary())\n",
    "print ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41cbaf",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed1509e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
